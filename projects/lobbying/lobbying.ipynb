{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from flatten_json import flatten\n",
    "from utils.io import dict_to_yaml\n",
    "from utils.io import yaml_to_dict\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from cleanco import basename\n",
    "from json import dumps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import postproc\n",
    "import matplotlib.colors as mc\n",
    "\n",
    "id = \"lgulden\"\n",
    "apikey = \"4d1a4bc3be920e859b3862a25d3725d741028d42\"\n",
    "data_gov_api_key = \"n4TEYUedn3STcnsxQi7JllzXZgfB6Dqg5pV2068E\"\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/config_ccs_lda.yml\"\n",
    ")\n",
    "term_list_dict = yaml_to_dict(config[\"search_term_list_path\"])\n",
    "law_list_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/ccs_laws.yml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticated_session = api_authenticate(\n",
    "    config[\"authentication_endpoint\"],\n",
    "    config[\"lda_username\"],\n",
    "    config[\"lda_apikey\"],\n",
    ")\n",
    "result = authenticated_session.get(\n",
    "    config[\"filings_endpoint\"],\n",
    "    params={\"filing_specific_lobbying_issues\": f\"{search_string}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_govt_entities(entity_endpoint: str, session: object):\n",
    "    \"\"\"Queries constants endpoint to get a standardized list of government entities\"\"\"\n",
    "    govt_entities = session.get(entity_endpoint, timeout=60)\n",
    "    entity_df = pd.DataFrame(govt_entities.json())\n",
    "    entities = sorted([x.lower() for x in list(entity_df[\"name\"])])\n",
    "    return entities\n",
    "\n",
    "\n",
    "def api_authenticate(\n",
    "    authentication_endpoint,\n",
    "    username,\n",
    "    apikey,\n",
    "    username_key=\"username\",\n",
    "    password_key=\"password\",\n",
    "):\n",
    "    \"\"\"logs in to the api using provided authentication endpoint and credentials\"\"\"\n",
    "    authenticated_session = requests.Session()\n",
    "\n",
    "    authenticated_session.post(\n",
    "        authentication_endpoint,\n",
    "        json={\n",
    "            username_key: username,\n",
    "            password_key: apikey,\n",
    "        },\n",
    "        timeout=60,\n",
    "    )\n",
    "\n",
    "    return authenticated_session\n",
    "\n",
    "\n",
    "def terms_present(phrase, term_list, find_any=True):\n",
    "    \"\"\"utility function to see if terms in terms_list are present in a given phrase\n",
    "    Args:\n",
    "        phrase: phrase to be searched\n",
    "        term_list: list of strings to be searched for within phrase\n",
    "        find_any: boolean -- true if function should return true if any of the terms are in the phrase;\n",
    "            false if the function should only return true if all terms are present\n",
    "    Returns:\n",
    "        int: 1 if one or more of the terms are present in phrase, 0 otherwise\n",
    "    \"\"\"\n",
    "    if not isinstance(phrase, str):\n",
    "        raise TypeError(\"phrase must be a string\")\n",
    "\n",
    "    if phrase is None:\n",
    "        return 0\n",
    "    n_present = 0\n",
    "    for term in term_list:\n",
    "        if not isinstance(term, str):\n",
    "            raise TypeError(\" all terms in term_list must be strings\")\n",
    "        if term.lower() in phrase.lower():\n",
    "            if find_any:\n",
    "                return 1\n",
    "            n_present += 1\n",
    "    if n_present == len(term_list):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def substitute(\n",
    "    x: str,\n",
    "    use_basename: bool = False,\n",
    "    re_types: str = r\"[^\\w\\s]\",\n",
    "    replace_str: str = \"\",\n",
    "):\n",
    "    \"\"\"wrapper function for regular expression substitute funciton, linked with basename lib\"\"\"\n",
    "    # use basename for company names\n",
    "    if not isinstance(x, str):\n",
    "        x = \"\"\n",
    "    if use_basename:\n",
    "        return basename(re.sub(re_types, replace_str, x))\n",
    "    # don't use basename for general strings\n",
    "    return re.sub(re_types, replace_str, x).rstrip().lstrip()\n",
    "\n",
    "\n",
    "def parse_client_names(\n",
    "    input_df, config, client_rename_col=\"client_rename\"\n",
    ") -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
    "    \"\"\"bespoke function for parsing organization names from LDA queries\n",
    "    Args:\n",
    "        input_df: input pandas dataframe (read raw from files saved after api access)\n",
    "        config: configuration dictionary containing details on how to handle names\n",
    "        client_rename_column: name for new column in dataframe that is returned\n",
    "    Returns:\n",
    "        output_df: processed column with renamed clients and removed organziations\n",
    "        client_name_rename_dict: dictionary used for renaming (contains original and new names)\n",
    "    \"\"\"\n",
    "    output_df = input_df.copy(deep=True)\n",
    "\n",
    "    starting_client_names = sorted(list(output_df.client_name.unique()))\n",
    "    client_names = sorted(list(output_df.client_name.unique()))\n",
    "    client_names = [\n",
    "        substitute(company_name, use_basename=True) for company_name in client_names\n",
    "    ]\n",
    "\n",
    "    # take rightmost component of client name\n",
    "    for term in config[\"take_terms_to_the_right_of_these_words\"]:\n",
    "        client_names = [x.split(term)[-1] for x in client_names]\n",
    "    # take leftmost component of client name\n",
    "    for term in config[\"take_terms_to_the_left_of_these_words\"]:\n",
    "        client_names = [x.split(term)[0] for x in client_names]\n",
    "    # remove words\n",
    "    for n in config[\"remove_these_phrases\"]:\n",
    "        client_names = [x.replace(n, \"\") for x in client_names]\n",
    "    # get rid of double spaces\n",
    "    client_names = [x.replace(\"  \", \" \") for x in client_names]\n",
    "    # trim spaces on ends of names\n",
    "    client_names = [x.rstrip().lstrip() for x in client_names]\n",
    "\n",
    "    # extract shorter, well-known names from longer names\n",
    "    for co in config[\"use_these_name_subsets_for_organiztions\"]:\n",
    "        client_names = [co if co in x else x for x in client_names]\n",
    "\n",
    "    # bespoke replacements and handling of mergers\n",
    "    for key, value in config[\"replace_names_on_left_with_names_on_right\"].items():\n",
    "        client_names = [x.replace(key, value) for x in client_names]\n",
    "\n",
    "    # make a renaming dictionary\n",
    "    client_name_rename_dict = dict(zip(starting_client_names, client_names))\n",
    "\n",
    "    # add the 'remove' companies to the rename dictionary\n",
    "    remove_companies = config[\"remove_companies_containing_these_terms\"]\n",
    "    for x in client_name_rename_dict.keys():\n",
    "        if terms_present(client_name_rename_dict[x], remove_companies, find_any=True):\n",
    "            client_name_rename_dict[x] = \"remove\"\n",
    "\n",
    "    # make new column with renames\n",
    "    output_df[client_rename_col] = [\n",
    "        client_name_rename_dict[x] for x in output_df.client_name\n",
    "    ]\n",
    "    output_df = output_df.loc[output_df[client_rename_col] != \"remove\"]\n",
    "\n",
    "    return output_df, client_name_rename_dict\n",
    "\n",
    "\n",
    "def get_smarties(\n",
    "    row: Union[pd.Series, List[Union[bool, int]]], names: List[str]\n",
    ") -> List[str]:\n",
    "    if isinstance(row, pd.Series):\n",
    "        return list(compress(names, row[names].values.tolist()))\n",
    "    if isinstance(row, list):\n",
    "        return list(compress(names, row))\n",
    "    raise TypeError(\"get_smarties argument 'row' must be a Pandas Series or a list\")\n",
    "\n",
    "\n",
    "def get_latest_filings(\n",
    "    df: pd.DataFrame, groupby_cols: List[str], date_col=\"filing_dt_posted\"\n",
    "):\n",
    "    \"\"\"get only the latest filing for a given lobbying firm, client, and quarter\"\"\"\n",
    "    if df[date_col].dtype == str:\n",
    "        df[date_col] = [dt.datetime.fromisoformat(d) for d in df[date_col]]\n",
    "\n",
    "    df.sort_values(by=date_col, ascending=False, inplace=True)\n",
    "\n",
    "    df = df.groupby(groupby_cols).first().reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def invert_sector_dict(sectors_path) -> Dict[str, str]:\n",
    "    \"\"\"reads in the sector assignment yaml to dict; inverts dict s.t. each company is a key\"\"\"\n",
    "    sector_assignments = yaml_to_dict(sectors_path)\n",
    "\n",
    "    all_companies = []\n",
    "    for _, value in sector_assignments.items():\n",
    "        all_companies = all_companies + value\n",
    "    # print(all_companies)\n",
    "\n",
    "    company_sector_dict = {}\n",
    "    for k, vv in sector_assignments.items():\n",
    "        for v in vv:\n",
    "            company_sector_dict = company_sector_dict | {v: k}\n",
    "\n",
    "    return company_sector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_info = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/config_ccs_lda.yml\"\n",
    ")\n",
    "groupby_cols = [\n",
    "    \"filing_year\",\n",
    "    \"filing_period\",\n",
    "    \"client_id\",\n",
    "    \"registrant_id\",\n",
    "    \"activity_id\",\n",
    "]\n",
    "entities = get_list_govt_entities(\n",
    "    config_info[\"entity_endpoint\"],\n",
    "    session=api_authenticate(\n",
    "        config_info[\"authentication_endpoint\"],\n",
    "        config_info[\"lda_username\"],\n",
    "        config_info[\"lda_apikey\"],\n",
    "    ),\n",
    ")\n",
    "remove_sector_descriptions = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sector_company_description_terms.yml\"\n",
    ")[\"remove\"]\n",
    "\n",
    "df_list = []\n",
    "rename_dict = {}\n",
    "for i in range(1, 19):  # 159):\n",
    "    api_results_df = pd.read_csv(\n",
    "        # f\"/Volumes/Samsung_T5/data/lobbying/ccslaws/ccs_lda_filings_{i}.csv\",\n",
    "        f\"/Volumes/Samsung_T5/data/lobbying/ccs/ccs_lda_filings_{i}.csv\",\n",
    "        index_col=[0],\n",
    "        # parse_dates=[\"filing_dt_posted\"],\n",
    "        dtype={\"filing_year\": int},\n",
    "        low_memory=False,\n",
    "    )\n",
    "    # remove unwanted filing types\n",
    "    api_results_df = api_results_df.loc[\n",
    "        [x[0] != \"R\" for x in api_results_df.filing_type]\n",
    "    ]\n",
    "\n",
    "    # parse company names, remove unwanted names, add to list\n",
    "    df, this_rename_dict = parse_client_names(\n",
    "        api_results_df, yaml_to_dict(config_info[\"organization_name_handling_path\"])\n",
    "    )\n",
    "\n",
    "    # append the rename dictionary to the whole thing\n",
    "    rename_dict = rename_dict | this_rename_dict\n",
    "    # compress entities into a single string column and get rid of entity columns\n",
    "    df[\"entities\"] = df[entities].T.apply(lambda x: dumps(get_smarties(x, entities)))\n",
    "    df.drop(entities, axis=1, inplace=True)\n",
    "    df[\"clean_description\"] = [\n",
    "        substitute(d, use_basename=True) for d in df[\"description\"]\n",
    "    ]\n",
    "    df[\"clean_client_general_description\"] = [\n",
    "        substitute(d, use_basename=False) for d in df[\"client_general_description\"]\n",
    "    ]\n",
    "    df[\"client_rename\"] = [\n",
    "        \"remove\" if terms_present(x, remove_sector_descriptions) else n\n",
    "        for x, n in zip(df.clean_client_general_description, df.client_rename)\n",
    "    ]\n",
    "    df[\"client_rename\"] = [\n",
    "        \"remove\" if terms_present(x, remove_sector_descriptions) else x\n",
    "        for x in df.client_rename\n",
    "    ]\n",
    "\n",
    "    df = get_latest_filings(df, groupby_cols)\n",
    "    df = df.loc[df.client_rename != \"remove\"]\n",
    "    df_list.append(df)\n",
    "\n",
    "ccs_df = pd.concat(df_list)\n",
    "ccs_df = get_latest_filings(ccs_df, groupby_cols)\n",
    "# fill in nans/nones with empty string for description and rename of client\n",
    "ccs_df.clean_client_general_description = (\n",
    "    ccs_df.clean_client_general_description.fillna(\"\")\n",
    ")\n",
    "ccs_df.client_rename = ccs_df.client_rename.fillna(\"\")\n",
    "ccs_df[\"batch\"] = \"ccs description and/or ccs specific laws and bills\"\n",
    "ccs_df.to_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccs_compiled.csv\")\n",
    "# ccs_df[\"batch\"] = \"relevant laws\"\n",
    "# ccs_df.to_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccslaws_compiled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join different query results into a single dataframe\n",
    "tmp_df = pd.read_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccs_compiled.csv\")\n",
    "law_df = pd.read_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccslaws_compiled.csv\")\n",
    "ccs_df = pd.concat([tmp_df, law_df])\n",
    "ccs_df.sort_values(by=[\"batch\"], ascending=True, inplace=True)\n",
    "ccs_df.drop_duplicates(\n",
    "    subset=[\"filing_uuid\", \"activity_id\"], keep=\"first\", inplace=True\n",
    ")\n",
    "ccs_df.reset_index(inplace=True)\n",
    "ccs_df.to_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccsall_compiled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out updated, merged, slightly processed ccsall\n",
    "ccs_df.clean_client_general_description = (\n",
    "    ccs_df.clean_client_general_description.fillna(\"\")\n",
    ")\n",
    "ccs_df.client_rename = ccs_df.client_rename.fillna(\"\")\n",
    "ccs_df.to_csv(\"/Volumes/Samsung_T5/data/lobbying/ccs/ccsall_compiled_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_df = pd.read_csv(\n",
    "    #    \"/Volumes/Samsung_T5/data/lobbying/ccs/ccsall_compiled.csv\", index_col=[0]\n",
    "    \"/Volumes/Samsung_T5/data/lobbying/ccs/ccsall_compiled_revised.csv\",\n",
    "    index_col=[0],\n",
    ")\n",
    "ccs_df.clean_client_general_description = (\n",
    "    ccs_df.clean_client_general_description.fillna(\"\")\n",
    ")\n",
    "ccs_df.client_rename = ccs_df.client_rename.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_dict = yaml_to_dict(\"sector_descriptions.yml\")\n",
    "sector_list = sorted(list(description_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "inverted_sector_dict = invert_sector_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "companies = [c.rstrip().lstrip() for c in list(inverted_sector_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_df.loc[\n",
    "    ~ccs_df.client_rename.isin(companies)\n",
    "    # & (ccs_df.clean_client_general_description == \"\")\n",
    "].client_rename.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, n in (\n",
    "    ccs_df.loc[\n",
    "        ~ccs_df.client_rename.isin(companies)\n",
    "        # & (ccs_df.clean_client_general_description == \"\")\n",
    "    ]\n",
    "    .clean_client_general_description.value_counts()\n",
    "    .items()\n",
    "):\n",
    "    # if (\"geo\" in c.lower()) | (\"college\" in c.lower()):\n",
    "    print(f\"- {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_dict = yaml_to_dict(\"sector_descriptions.yml\")\n",
    "tmp = sorted(\n",
    "    [\n",
    "        f\"'{x.lower()}'\" if (x[0] == \" \") | (x[-1] == \" \") else f\"{x.lower()}\"\n",
    "        for x in list(set(description_dict[\"remove these organizations\"][\"keep\"]))\n",
    "    ]\n",
    ")\n",
    "for t in tmp:\n",
    "    print(f\" - {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND SPECIFIC INDUSTRIES\n",
    "which_sector = \"oil and gas\"  # \"auto and transportation\"  # \"renewable energy\"  # \"chemicals\"  # \"cement\"  # \"engineering, technology, and consulting\"  # \"nuclear\"  # \"remove these organizations\"\n",
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "inverted_sector_dict = invert_sector_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "companies = [c.rstrip().lstrip() for c in list(inverted_sector_dict.keys())]\n",
    "description_dict = yaml_to_dict(\"sector_descriptions.yml\")\n",
    "sector_list = sorted(list(description_dict.keys()))\n",
    "org_names = []\n",
    "companies_list = companies  # list(inverted_sector_dict.keys())\n",
    "for n, row in ccs_df.iterrows():\n",
    "    phrase = row[\"clean_client_general_description\"].lower()\n",
    "    client_rename = row[\"client_rename\"].lower()\n",
    "    if row[\"client_rename\"] in companies:\n",
    "        pass\n",
    "    elif terms_present(\n",
    "        phrase, description_dict[which_sector][\"exclude\"], find_any=True\n",
    "    ):\n",
    "        pass\n",
    "    elif terms_present(\n",
    "        client_rename,\n",
    "        description_dict[which_sector][\"exclude\"],\n",
    "        find_any=True,\n",
    "    ):\n",
    "        pass\n",
    "    elif terms_present(phrase, description_dict[which_sector][\"keep\"], find_any=True):\n",
    "        org_names.append((row[\"client_rename\"]))\n",
    "    elif terms_present(\n",
    "        client_rename, description_dict[which_sector][\"keep\"], find_any=True\n",
    "    ):\n",
    "        org_names.append((row[\"client_rename\"]))\n",
    "org_list = sorted(list(set(org_names)))\n",
    "for i in org_list:\n",
    "    if i.rstrip().lstrip() in companies:\n",
    "        pass\n",
    "    else:\n",
    "        # print(f\"- {i}\")\n",
    "        print(f\"'{i}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "inverted_sector_dict = invert_sector_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "companies = [c.rstrip().lstrip() for c in list(inverted_sector_dict.keys())]\n",
    "not_assigned = sorted(list(set(ccs_df.client_rename.unique()) - set(companies)))\n",
    "for c in not_assigned:\n",
    "    descriptions = list(\n",
    "        ccs_df.loc[ccs_df.client_rename == c].clean_client_general_description.unique()\n",
    "    )\n",
    "    term = \"aero\"\n",
    "    # if (term in c.lower()) | (any([term in x.lower() for x in descriptions])):\n",
    "    print(f\"- {c}\")\n",
    "    #    print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "for k, v in sectors_dict.items():\n",
    "    sectors_dict[k] = sorted(list(set(v)))\n",
    "\n",
    "dict_to_yaml(\n",
    "    sectors_dict,\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors_2.yml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'org_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m companies \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;241m.\u001b[39mlstrip() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(inverted_sector_dict\u001b[38;5;241m.\u001b[39mkeys())]\n\u001b[1;32m      8\u001b[0m not_assigned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(ccs_df\u001b[38;5;241m.\u001b[39mclient_rename\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(companies)))\n\u001b[0;32m---> 10\u001b[0m list_of_companies \u001b[38;5;241m=\u001b[39m \u001b[43morg_list\u001b[49m\n\u001b[1;32m     11\u001b[0m list_of_companies \u001b[38;5;241m=\u001b[39m not_assigned\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# list_of_companies = sorted(list(set(sectors_dict[which_sector])))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'org_list' is not defined"
     ]
    }
   ],
   "source": [
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "inverted_sector_dict = invert_sector_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "companies = [c.rstrip().lstrip() for c in list(inverted_sector_dict.keys())]\n",
    "not_assigned = sorted(list(set(ccs_df.client_rename.unique()) - set(companies)))\n",
    "\n",
    "list_of_companies = org_list\n",
    "list_of_companies = not_assigned\n",
    "# list_of_companies = sorted(list(set(sectors_dict[which_sector])))\n",
    "for org in list_of_companies:\n",
    "    descriptions = list(\n",
    "        ccs_df.loc[\n",
    "            ccs_df.client_rename == org\n",
    "        ].clean_client_general_description.unique()\n",
    "    )\n",
    "    term = \"flight\"\n",
    "    if (term in org.lower()) | any([term in x for x in descriptions]):\n",
    "        print(f\"- {org}\")\n",
    "        print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_assigned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it back in and print\n",
    "sectors_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "for i in sorted(list(set(sectors_dict[which_sector]))):\n",
    "    print(f\"- {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = ccs_df.loc[\n",
    "    [\n",
    "        (\n",
    "            x\n",
    "            == \"MRGCD delivers irrigation water to Pueblos farmers and maintains river habitat\"\n",
    "        )\n",
    "        and (n in org_list)\n",
    "        for x, n in zip(ccs_df.clean_client_general_description, ccs_df.client_rename)\n",
    "    ]\n",
    "].client_rename.unique()\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_df.loc[ccs_df.client_rename == ar[0]].clean_client_general_description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sectors_dict[\"auto and transportation\"]).intersection(\n",
    "    set(sectors_dict[\"remove these organizations\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VINEYARD WIND, LLC', 'COLLEGE SAVINGS FOUNDATION',\n",
       "       'OVINTIV INC (FKA ENCANA OIL & GAS (USA) INC)', 'VINYL INSTITUTE',\n",
       "       'CITY OF IRVINE, CA', 'IRVINE RANCH WATER DISTRICT',\n",
       "       'VINGROUP USA, LLC (DCA VINFAST)', 'CITY OF IRVINE',\n",
       "       \"PIKE ASSOCIATES, LLC OBO WOODS HOLE MARTHA'S VINEYARD NANTUCKET STEAMSHIP AUTH.\",\n",
       "       \"WOODS HOLE, MARTHA'S VINEYARD AND NANTUCKET STEAMSHIP AUTHORITY\",\n",
       "       'MOTHERS AGAINST DRUNK DRIVING',\n",
       "       'POPLICUS INCORPORATED D/B/A GOVINI',\n",
       "       'LIVINGSTON GROUP LLC - (CLIENT: MAYO CLINIC)',\n",
       "       'THE LIVINGSTON GROUP, LLC. - (CLIENT:  CITY OF NEW ORLEANS )',\n",
       "       'ASHLAND INC ON BEHALF OF THE LIVINGSTON GROUP', 'GOLDEN LIVING',\n",
       "       'IRVING OIL LTD', 'COALITION OF URBAN SERVING UNIVERSITIES',\n",
       "       'ARVINMERITOR, INC.', 'CONFERENCE OF PROVINCIALS OF NORTH AMERICA',\n",
       "       'SAVINGS COALITION OF AMERICA', 'SAVING OUR SERVICE',\n",
       "       \"LIVINGSTON GROUP (FOR PLAQUEMINES PARISH SHERIFF'S OFFICE)\",\n",
       "       'AMERICAN MOVING AND STORAGE ASSOCIATION'], dtype=object)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccs_df.loc[[\"VIN\" in x for x in ccs_df.client_rename]].client_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AMERICAN FUEL & PETROCHEMICAL MANUFACTURERS':'AMERICAN FUEL PETROCHEMICAL MANUFACTURERS',\n",
      "'AMERICAN FUEL AND PETROCHEMICAL MANUFACTURERS (AFPM)':'AMERICAN FUEL AND PETROCHEMICAL MANUFACTURERS AFPM',\n",
      "'AMERICAN FUEL & PETROCHEMICAL MANUFACTURERS (AFPM)':'AMERICAN FUEL PETROCHEMICAL MANUFACTURERS AFPM',\n"
     ]
    }
   ],
   "source": [
    "for co in [\"AMERICAN FUEL PETROCHEMICAL MANUFACTURERS\"]:\n",
    "    for i in list(\n",
    "        ccs_df.loc[\n",
    "            ccs_df.client_rename\n",
    "            == co\n",
    "            # ].clean_client_general_description.unique()\n",
    "        ].client_name.unique()\n",
    "    ):\n",
    "        if \"ELEPHANT\" in i:\n",
    "            print(f\"'{i}':'DOW',\")\n",
    "        else:\n",
    "            print(f\"'{i}':'{substitute(i,use_basename=True)}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland_replace_dict = yaml_to_dict('/Users/lindseygulden/dev/leg-up-private/projects/lobbying/company_name_replacements.yml')\n",
    "\n",
    "ccs_df[\"client_rename\"] = [\n",
    "    portland_replace_dict[x] if x in list(portland_replace_dict.keys()) else r\n",
    "    for x, r in zip(ccs_df.client_name, ccs_df.client_rename)\n",
    "]\n",
    "dict_to_yaml(portland_replace_dict, \"company_name_replacements.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, whichco in enumerate(ar):\n",
    "    print(whichco)\n",
    "    print(\n",
    "        ccs_df.loc[\n",
    "            ccs_df.client_rename\n",
    "            == whichco\n",
    "            # ].clean_client_general_description.unique()\n",
    "        ].client_name.unique()\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_descriptions_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sector_company_description_terms.yml\"\n",
    ")\n",
    "sector_mapping = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "mapped_orgs = []\n",
    "for v in sector_mapping.values():\n",
    "    mapped_orgs = mapped_orgs + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. air transit\n",
      "1. land transit\n",
      "2. fuel cell\n",
      "3. water transit\n",
      "4. carbon\n",
      "5. ccs\n",
      "6. cement\n",
      "7. business advocacy\n",
      "8. chemicals, refining, and plastics\n",
      "9. clean hydrogen\n",
      "10. water\n",
      "11. coal\n",
      "12. engineering, technology, and consulting\n",
      "13. individuals\n",
      "14. environmental\n",
      "15. other\n",
      "16. finance\n",
      "17. biofuels\n",
      "18. food and agriculture\n",
      "19. green hydrogen\n",
      "20. higher education\n",
      "21. think tanks and issue advocacy\n",
      "22. independent research organization\n",
      "23. iron and steel\n",
      "24. labor union\n",
      "25. government\n",
      "26. nuclear\n",
      "27. mining and metals\n",
      "28. oil and gas\n",
      "29. oilfield services\n",
      "30. paper products\n",
      "31. pipelines\n",
      "32. power generation and utilities\n",
      "33. railway\n",
      "34. renewable energy\n",
      "35. professional societies\n",
      "36. hvac\n",
      "37. remove these organizations\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(list(sector_mapping.keys())):\n",
    "    print(f\"{i}. {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rename_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[285], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mrename_dict\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      2\u001b[0m new_cos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m new_vals \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mapped_orgs])))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(new_cos):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# if \"oil\" in n.lower():\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rename_dict' is not defined"
     ]
    }
   ],
   "source": [
    "new_vals = list(rename_dict.values())\n",
    "new_cos = sorted(list(set([x for x in new_vals if x not in mapped_orgs])))\n",
    "for i, n in enumerate(new_cos):\n",
    "    # if \"oil\" in n.lower():\n",
    "    print(f\"- {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carbon capture', 'co2 capture', 'c02 capture', 'co2 sequestration', 'c02 sequestration', 'co2 storage', 'c02 storage', 'c02 pipe', 'co2 pipe', 'capture of carbon oxides', 'carbon dioxide capture', 'capture and store', 'carbon utilization', 'carbon dioxide use and storage', 'carbon dioxide utilization', 'co2 utilization', 'co2 use and storage', 'capture and storage', 'capture transportation and storage', 'capture transport and storage', 'capture transport utilization and storage', 'capture transport use and storage', 'capture transport use and sequestration', 'capture transport utilization and sequestration', 'capture transport and store', 'co2 transportation and storage', 'geologic sequestration', 'geologic storage', 'capture of carbon dioxide', 'carbon sequestration', 'carbon dioxide sequestration', 'carbon oxide sequestration', 'capture of co2', 'hydrogen hub', 'clean hydrogen', 'blue hydrogen', 'capture and sequestration', 'capture utilization and sequestration', 'capture use and storage', 'capture use and sequestration', 'CCS', 'C C S', 'C C U S', 'CCS', 'CCUS', 'CCU', '45Q', '45 Q', '45V', '45 V', 'clean coal', 'cleancoal', 'enhanced oil recovery', 'EOR', 'tertiary recovery', 'tertiary oil recovery', 'carbon management', 'carbonmanagement', 'co2 management', 'co2management', 'low carbon solutions', 'carbon dioxide pipe', 'co2 pipe', 'underground injection control', 'class vi well', 'classvi well', 'storage of co2', 'injection of co2', 'storage of c02', 'injection of c02', 'co2 injection', 'carbon removal', 'carbon reuse', 'carbon conversion', 'industrial innovation initiative']\n",
      "[['carbon removal', 'sequestration'], ['carbon removal', 'utilization'], ['carbon removal', 'storage'], ['hydrogen', 'greenhouse'], ['CDR', 'inject'], ['CDR', 'store'], ['CDR', 'geologic'], ['EPA', 'UIC'], ['class vi', 'permit'], ['class vi', 'primacy'], ['classvi', 'permit'], ['classvi', 'primacy'], ['primacy', 'louisiana'], ['primacy', 'texas'], ['primacy', 'gulf'], ['primacy', '117169'], ['primacy', '11758'], ['life cycle analysis', 'carbon'], ['monitoring reporting and verification', 'carbon'], ['life cycle analysis', 'co2'], ['monitoring reporting and verification', 'co2']]\n"
     ]
    }
   ],
   "source": [
    "search_term_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/search_term_list.yml\"\n",
    ")\n",
    "\n",
    "search_terms = search_term_dict[\"search_term_list\"]\n",
    "probably_ccs = search_term_dict[\"probably_ccs\"]\n",
    "maybe_ccs = search_term_dict[\"maybe_ccs\"]\n",
    "\n",
    "terms = []\n",
    "for t in search_terms:\n",
    "    if \",\" in t:\n",
    "        terms.append(t.replace('\"', \"\").split(\",\"))\n",
    "    else:\n",
    "        terms.append([t.replace('\"', \"\")])\n",
    "\n",
    "terms = [[substitute(t) for t in tt] for tt in terms]\n",
    "\n",
    "single_terms = []\n",
    "multiple_terms = []\n",
    "for x in terms:\n",
    "    if len(x) == 1:\n",
    "        single_terms.append(x[0])\n",
    "    else:\n",
    "        multiple_terms.append(x)\n",
    "print(single_terms)\n",
    "print(multiple_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carbon Capture and Storage Early Deployment Act', 'Carbon Capture Utilization and Storage Tax Credit Amendments Act', 'Carbon Capture and Storage Technology Act', 'Carbon Capture and Storage Research Development and Demonstration Act', 'Enhancing Fossil Fuel Energy Carbon Technology Act', 'Carbon Capture Modernization Act', 'EFFECT Act', '110140', 'Advanced Clean Coal Technology Investment in Our Nation Act', 'Responsible Use of Coal Act', 'ACCTION Act', 'Utilizing Significant Emissions with Innovative Technologies', ' USE IT', '116260', 'Carbon Capture Modernization Act', 'Fossil Energy Research and Development Act', 'Boxer Substitute Amendment', 'BoxerKerry', 'Boxer Kerry', 'Storing CO2 and Lowering Emissions Act', 'SCALE Act', 'CCU Parity', 'Department of Energy Clean Hydrogen and Fuel Cell Research Development and Demonstration Act', 'Energy Sector Innovation Credit Act']\n"
     ]
    }
   ],
   "source": [
    "ccs_bills = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/ccs_laws.yml\"\n",
    ")[\"mostly_ccs_provisions\"]\n",
    "ccs_bills = [re.sub(r\"[^\\w\\s]\", \"\", x) for x in ccs_bills]\n",
    "print(ccs_bills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ccs_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clean_description = df.clean_description.fillna(\" \")\n",
    "auto_transport_descriptions = [\n",
    "    \"auto\",\n",
    "    \"car\",\n",
    "    \"transport\",\n",
    "    \"engine\",\n",
    "    \"vehicle\",\n",
    "    \"shipping\",\n",
    "    \"cargo\",\n",
    "    \"airline\",\n",
    "    \"airplane\",\n",
    "]\n",
    "ccs_company_descriptions = [\n",
    "    \"capture\",\n",
    "    \"ccs\",\n",
    "    \"ccus\",\n",
    "    \"storage of co2\",\n",
    "    \"sequestration\",\n",
    "    \"greenhouse gas reduction\",\n",
    "]\n",
    "iron_and_steel_descriptions = [\n",
    "    \"iron\",\n",
    "    \"steel\",\n",
    "]\n",
    "utility_descriptions = [\n",
    "    \"utility\",\n",
    "    \"electricity\",\n",
    "    \"power company\",\n",
    "    \"power and light\",\n",
    "    \"power light\",\n",
    "    \"utilities\",\n",
    "    \"electric\",\n",
    "    \"power generation\",\n",
    "    \"power provider\",\n",
    "    \"energy provider\",\n",
    "    \"energy generation\",\n",
    "    \"energy production\",\n",
    "    \"energy transmission\",\n",
    "    \"energy distribution\",\n",
    "    \"generation and distribution\",\n",
    "    \"electric and natural gas\",\n",
    "    \"transmission and distribution\",\n",
    "    \"production and distribution\",\n",
    "    \"transmission provider\",\n",
    "]\n",
    "oil_and_gas_descriptions = [\n",
    "    \"oil and gas\",\n",
    "    \"natural gas\",\n",
    "    \"midstream\",\n",
    "    \"drilling\",\n",
    "    \"downstream\",\n",
    "    \"upstream\",\n",
    "    \"fuel\",\n",
    "    \"pipeline\",\n",
    "    \"refinery\",\n",
    "    \"refining\",\n",
    "    \"exploration and production\",\n",
    "    \"exploration production\",\n",
    "    \"E&P\",\n",
    "    \"E & P\",\n",
    "    \"oil\",\n",
    "    \"petroleum\",\n",
    "]\n",
    "df[\"land_transport\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        auto_transport_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"land transit\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"water_transport\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        auto_transport_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"water transit\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"air_transport\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        auto_transport_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"air transit\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"fuel_cell\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        auto_transport_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"fuel cell\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"steel_company\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        iron_and_steel_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"iron and steel\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"ccs_company\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        ccs_company_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"ccs\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"utility\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        utility_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"power generation and utilities\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"oilandgas\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        oil_and_gas_descriptions,\n",
    "    )\n",
    "    | (n in sector_mapping[\"oil and gas\"])\n",
    "    for x, n in zip(df[\"clean_client_general_description\"], df[\"client_rename\"])\n",
    "]\n",
    "df[\"probably ccs\"] = [terms_present(x, probably_ccs) for x in df.clean_description]\n",
    "df[\"maybe ccs\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        maybe_ccs,\n",
    "    )\n",
    "    for x in df.clean_description\n",
    "]\n",
    "\n",
    "df[\"eor\"] = [\n",
    "    terms_present(x, [\"EOR\", \"enhanced oil recovery\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"sustainable\"] = [\n",
    "    terms_present(x, [\"sustainable\", \"sustainability\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"permitting\"] = [\n",
    "    terms_present(x, [\"permit\", \"permitting\", \"permits\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"carbon tax\"] = [\n",
    "    terms_present(x, [\"carbon tax\", \"tax on carbon\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"recycle\"] = [\n",
    "    terms_present(x, [\"recycle\", \"recycling\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"hydrogen\"] = [\n",
    "    terms_present(\n",
    "        x, [\"hydrogen\", \"lowcarbon fuel\", \"low carbon fuel\", \"fuelcell\", \"fuel cell\"]\n",
    "    )\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"nuclear\"] = [terms_present(x, [\"nuclear\", \"uranium\"]) for x in df.clean_description]\n",
    "df[\"carbon_management\"] = [\n",
    "    terms_present(x, [\"carbon management\", \"carbonmanagement\"])\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"clean_energy\"] = [terms_present(x, [\"clean energy\"]) for x in df.clean_description]\n",
    "df[\"biofuels\"] = [\n",
    "    terms_present(x, [\"ethanol\", \"bioethanol\", \"biofuel\", \"biodiesel\"])\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"climate\"] = [terms_present(x, [\"climate\"]) for x in df.clean_description]\n",
    "df[\"energy security\"] = [\n",
    "    terms_present(x, [\"energy security\"]) for x in df.clean_description\n",
    "]\n",
    "\n",
    "df[\"low_carbon\"] = [\n",
    "    terms_present(x, [\"low carbon\", \"low emission\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"direct air\"] = [\n",
    "    terms_present(x, [\"directair\", \"direct air\", \"air capture\"])\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"tax\"] = [terms_present(x, [\"tax\"]) for x in df.clean_description]\n",
    "df[\"carbon_tax\"] = [\n",
    "    terms_present(x, [\"carbon tax\", \"carbontax\", \"tax on co2\", \"tax on carbon\"])\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"coal\"] = [terms_present(x, [\"coal\"]) for x in df.clean_description]\n",
    "df[\"clean coal\"] = [\n",
    "    terms_present(x, [\"clean coal\", \"cleancoal\"]) for x in df.clean_description\n",
    "]\n",
    "df[\"ccs_single\"] = [terms_present(x, single_terms) for x in df.clean_description]\n",
    "df[\"ccs_double\"] = [\n",
    "    any([terms_present(x, y, find_any=False) for y in multiple_terms])\n",
    "    for x in df.clean_description\n",
    "]\n",
    "df[\"ccs_description\"] = [\n",
    "    max(sgl, dbl) for sgl, dbl in zip(df[\"ccs_single\"], df[\"ccs_double\"])\n",
    "]\n",
    "\n",
    "df[\"ccs_bills\"] = [terms_present(x, ccs_bills) for x in df.clean_description]\n",
    "df[\"definitely_ccs\"] = [\n",
    "    1 if (d + b) > 0 else 0 for d, b in zip(df.ccs_description, df.ccs_bills)\n",
    "]\n",
    "df[\"likely_ccs\"] = [\n",
    "    1 if (d + b + p + c) > 0 else 0\n",
    "    for d, b, p, c in zip(\n",
    "        df.ccs_description, df.ccs_bills, df[\"probably ccs\"], df.ccs_company\n",
    "    )\n",
    "]\n",
    "df[\"potentially_ccs\"] = [\n",
    "    1 if (d + m + b + p + c) > 0 else 0\n",
    "    for d, b, m, p, c in zip(\n",
    "        df.ccs_description,\n",
    "        df.ccs_bills,\n",
    "        df[\"maybe ccs\"],\n",
    "        df[\"probably ccs\"],\n",
    "        df.ccs_company,\n",
    "    )\n",
    "]\n",
    "df[\"net\"] = [\n",
    "    terms_present(\n",
    "        x,\n",
    "        [\n",
    "            \"negative emissions technology\",\n",
    "            \"negative emissions technologies\",\n",
    "            \"negative emission technology\",\n",
    "            \"negative emission technologies\",\n",
    "        ],\n",
    "    )\n",
    "    for x in df.clean_description\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_transport         8269\n",
       "land_transport       14854\n",
       "water_transport       7010\n",
       "oilandgas            13078\n",
       "utility              29297\n",
       "steel_company         3902\n",
       "ccs_company           1183\n",
       "sustainable           5208\n",
       "probably ccs         11723\n",
       "maybe ccs            20135\n",
       "nuclear               5174\n",
       "permitting            7907\n",
       "low_carbon            1329\n",
       "ccs_description      13298\n",
       "definitely_ccs       17153\n",
       "likely_ccs           20653\n",
       "potentially_ccs      34366\n",
       "tax                  33219\n",
       "carbon_tax             607\n",
       "biofuels              4292\n",
       "direct air             247\n",
       "clean coal            1281\n",
       "clean_energy         16652\n",
       "carbon_management      116\n",
       "hydrogen              4187\n",
       "recycle               2713\n",
       "carbon tax             607\n",
       "climate              14869\n",
       "energy security       4886\n",
       "ccs_bills             5369\n",
       "net                      0\n",
       "eor                   1636\n",
       "dtype: object"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\n",
    "    [\n",
    "        \"air_transport\",\n",
    "        \"land_transport\",\n",
    "        \"water_transport\",\n",
    "        \"oilandgas\",\n",
    "        \"utility\",\n",
    "        \"steel_company\",\n",
    "        \"ccs_company\",\n",
    "        \"sustainable\",\n",
    "        \"probably ccs\",\n",
    "        \"maybe ccs\",\n",
    "        \"nuclear\",\n",
    "        \"permitting\",\n",
    "        \"low_carbon\",\n",
    "        \"ccs_description\",\n",
    "        \"definitely_ccs\",\n",
    "        \"likely_ccs\",\n",
    "        \"potentially_ccs\",\n",
    "        \"tax\",\n",
    "        \"carbon_tax\",\n",
    "        \"biofuels\",\n",
    "        \"direct air\",\n",
    "        \"clean coal\",\n",
    "        \"clean_energy\",\n",
    "        \"carbon_management\",\n",
    "        \"hydrogen\",\n",
    "        \"recycle\",\n",
    "        \"carbon tax\",\n",
    "        \"climate\",\n",
    "        \"energy security\",\n",
    "        \"ccs_bills\",\n",
    "        \"net\",\n",
    "        \"eor\",\n",
    "    ]\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apportion total lobbying dollars spent (on filing) to individual lobbying activities, using two methods\n",
    "df[\"activity_apportioned_usd\"] = [\n",
    "    usd / number_lobbying\n",
    "    for usd, number_lobbying in zip(\n",
    "        df.dollars_spent_lobbying, df.total_number_lobbying_activities\n",
    "    )\n",
    "]\n",
    "df[\"lobbyist_apportioned_usd\"] = [\n",
    "    usd * (n_activity_lobbyists / total_lobbyists)\n",
    "    if total_lobbyists > 0\n",
    "    else activity_apportioned\n",
    "    for usd, n_activity_lobbyists, total_lobbyists, activity_apportioned in zip(\n",
    "        df.dollars_spent_lobbying,\n",
    "        df.n_lobbyists_for_activity,\n",
    "        df.total_number_of_lobbyists_on_filing,\n",
    "        df.activity_apportioned_usd,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lobbyist_apportioned_usd    1.844476e+09\n",
       "activity_apportioned_usd    1.616863e+09\n",
       "dtype: float64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df.ccs_description == 1)\n",
    "    | (df.ccs_company == 1)\n",
    "    | (df.definitely_ccs == 1)\n",
    "    | (df[\"probably ccs\"] == 1)\n",
    "    | ((df.oilandgas == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.utility == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.air_transport == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.land_transport == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.water_transport == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.biofuels == 1) & (df[\"maybe ccs\"] == 1))\n",
    "    | ((df.steel_company == 1) & (df[\"maybe ccs\"] == 1))\n",
    "][[\"lobbyist_apportioned_usd\", \"activity_apportioned_usd\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'maybe ccs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'maybe ccs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[292], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[\n\u001b[0;32m----> 2\u001b[0m     (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaybe ccs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m&\u001b[39m ((df\u001b[38;5;241m.\u001b[39moilandgas \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m (df\u001b[38;5;241m.\u001b[39mutility \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m&\u001b[39m (df\u001b[38;5;241m.\u001b[39mccs_description \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m ]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_rename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'maybe ccs'"
     ]
    }
   ],
   "source": [
    "for i, row in df.loc[\n",
    "    (df[\"maybe ccs\"] == 1)\n",
    "    & ((df.oilandgas == 1) | (df.utility == 1))\n",
    "    & (df.ccs_description == 0)\n",
    "].iterrows():\n",
    "    print(f\"{row['client_rename']}: {row['clean_description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.loc[\n",
    "    (df[\"probably ccs\"] == 1) & (df.oilandgas == 0) & (df.ccs_description == 0)\n",
    "].iterrows():\n",
    "    print(f\"{row['client_rename']}: {row['clean_description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"potentially ccs\"] == 1][\n",
    "    [\"lobbyist_apportioned_usd\", \"activity_apportioned_usd\"]\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_assignments = yaml_to_dict(\"sectors.yml\")\n",
    "\n",
    "\n",
    "all_companies = []\n",
    "for _, value in sector_assignments.items():\n",
    "    all_companies = all_companies + value\n",
    "print(all_companies)\n",
    "\n",
    "company_sector_dict = {}\n",
    "for k, vv in sector_assignments.items():\n",
    "    for v in vv:\n",
    "        company_sector_dict = company_sector_dict | {v: k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_sector_dict = invert_sector_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/sectors.yml\"\n",
    ")\n",
    "lumped_sector_dict = yaml_to_dict(\n",
    "    \"/Users/lindseygulden/dev/leg-up-private/projects/lobbying/lumped_sectors.yml\"\n",
    ")[\"lumped_sector_assignments\"]\n",
    "df[\"sector\"] = df[\"client_rename\"].copy()\n",
    "df[\"sector\"] = [company_sector_dict[c] for c in df.sector]\n",
    "df[\"lumped_sector\"] = [lumped_sector_dict[c] for c in df.sector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['lumped_sector'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[309], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m definitely_ccs_by_year_sector_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefinitely_ccs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiling_year\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlumped_sector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlobbyist_apportioned_usd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiling_year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlumped_sector\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiling_year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlobbyist_apportioned_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m all_by_year_sector_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m     df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiling_year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlumped_sector\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlobbyist_apportioned_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiling_year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlumped_sector\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/projects-7_KjhAaO-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['lumped_sector'] not in index\""
     ]
    }
   ],
   "source": [
    "definitely_ccs_by_year_sector_df = (\n",
    "    df.loc[df[\"definitely_ccs\"] == 1][\n",
    "        [\"filing_year\", \"lumped_sector\", \"lobbyist_apportioned_usd\"]\n",
    "    ]\n",
    "    .groupby([\"filing_year\", \"lumped_sector\"])\n",
    "    .sum()\n",
    "    .sort_values(by=[\"filing_year\", \"lobbyist_apportioned_usd\"], ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "all_by_year_sector_df = (\n",
    "    df[[\"filing_year\", \"lumped_sector\", \"lobbyist_apportioned_usd\"]]\n",
    "    .groupby([\"filing_year\", \"lumped_sector\"])\n",
    "    .sum()\n",
    "    .sort_values(by=[\"filing_year\", \"lobbyist_apportioned_usd\"], ascending=False)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order = sorted(list(set(lumped_sector_dict.values())))\n",
    "\n",
    "colors = [\n",
    "    \"tab:green\",\n",
    "    \"tab:blue\",\n",
    "    \"darkorange\",\n",
    "    \"tab:purple\",\n",
    "    \"magenta\",\n",
    "    \"tab:red\",\n",
    "    \"crimson\",\n",
    "    \"dimgrey\",\n",
    "    \"rebeccapurple\",\n",
    "    \"teal\",\n",
    "    \"darkblue\",\n",
    "]\n",
    "color_palette = sns.color_palette(colors)\n",
    "palette = color_palette\n",
    "fig, ax = plt.subplots(2, 1, figsize=(16, 10))\n",
    "sns.barplot(\n",
    "    ax=ax[0],\n",
    "    data=definitely_ccs_by_year_sector_df,\n",
    "    x=\"filing_year\",\n",
    "    y=\"lobbyist_apportioned_usd\",\n",
    "    hue=\"lumped_sector\",\n",
    "    palette=color_palette,\n",
    "    hue_order=hue_order,\n",
    ")\n",
    "ax[0].grid()\n",
    "ax[0].legend(ncol=2)\n",
    "ax[0].set_xlim([5, 24])\n",
    "\n",
    "sns.barplot(\n",
    "    ax=ax[1],\n",
    "    data=all_by_year_sector_df,\n",
    "    x=\"filing_year\",\n",
    "    y=\"lobbyist_apportioned_usd\",\n",
    "    hue=\"lumped_sector\",\n",
    "    palette=color_palette,\n",
    "    hue_order=hue_order,\n",
    ")\n",
    "ax[1].grid()\n",
    "ax[1].legend(ncol=2, loc=\"center\")\n",
    "ax[1].set_xlim([5, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.client_rename.loc[~df.client_rename.isin(all_companies)].unique():\n",
    "    print(x.replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.clean_description.value_counts().items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.client_general_description.fillna(\"\", inplace=True)\n",
    "df.loc[\n",
    "    [\n",
    "        (\"ohio\" in x.lower())  # | (\"e&p\" in x.lower())\n",
    "        # for x in df.client_general_description\n",
    "        for x in df.client_rename\n",
    "    ]\n",
    "].client_rename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.client_rename.value_counts().items():\n",
    "    print(f\"{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"lobbyist_apportioned_usd\", \"client_rename\"]].loc[df.ccs == 1].groupby(\n",
    "    \"client_rename\"\n",
    ").sum().sort_values(by=\"lobbyist_apportioned_usd\", ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenwashing_df.filing_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenwashing_df.loc[greenwashing_df.ccs == 1].groupby(\n",
    "    \"filing_id\"\n",
    ").first().reset_index().groupby(\"who_is_lobbying\")[\"dollars_spent_lobbying\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_entities = [x for x in df.columns if x in entities]\n",
    "tmp = df[xom_entities].sum()\n",
    "subset_entities = list(tmp[tmp > 0].index)\n",
    "greenwashing_df = df.loc[df.ccs == 1].copy()\n",
    "greenwashing_df[subset_entities].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string = '\"carbon capture\"OR\"capture of carbon\"OR\"capture of co2\"OR\"CCUS\"OR\"CCS\"OR\"storage of carbon dioxide\"OR\"storage of co2\"OR\"capture and sequestration of carbon dioxide\"OR\"capture and sequestration of co2\"OR\"blue hydrogen\"OR\"hydrogen hub\"OR\"clean hydrogen\"OR\"45Q\"OR\"45V\"OR\"inflation reduction act\"OR\"117-169\"OR\"117-58\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_filings = f\"https://lda.senate.gov/api/v1/filings/?filing_specific_lobbying_issues={search_string}&filing_period=year_end\"\n",
    "\n",
    "f = requests.get(query_filings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info about congress.gov search for bills with ccs relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query for congress.gov search\n",
    "https://www.congress.gov/u/ISk7JcnkfFMeJIdw4sMwB\n",
    "\n",
    "# \"carbon capture\" OR \"capture of carbon\" OR \"CCUS\" OR \"CCS\" OR \"storage of carbon dioxide\" OR \"storage of co2\" OR \"sequestration of carbon dioxide\" OR \"sequestration of co2\" OR \"blue hydrogen\" OR \"clean hydrogen\" OR \"45Q\" OR \"45V\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_word_cloud = [\n",
    "    x.replace(\"Discussions related to\", \"\")\n",
    "    .replace(\"provisions\", \"\")\n",
    "    .replace(\"Provisions\", \"\")\n",
    "    for x in df.description.to_list()\n",
    "]\n",
    "xom_word_cloud = [\n",
    "    x.replace(\"related\", \"\")\n",
    "    .replace(\"Related\", \"\")\n",
    "    .replace(\"issues\", \"\")\n",
    "    .replace(\"provisions related\", \"\")\n",
    "    for x in xom_word_cloud\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "word_cloud = WordCloud(background_color=\"white\")\n",
    "word_cloud.generate(\" \".join(xom_word_cloud))\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(word_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"lobbyist_registrant_name\",\n",
    "        \"client_name\",\n",
    "        \"who_is_lobbying\",\n",
    "        \"general_issue_code\",\n",
    "        \"description\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_congress = f\"https://api.congress.gov/v3/bill/118/hr/1262/summaries?format=json&api_key={data_gov_api_key}\"\n",
    "s = requests.get(query_congress)\n",
    "s.json()[\"summaries\"][-1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dollars_spent(income, expense):\n",
    "    if (income is None) & (expense is None):\n",
    "        return \"income and expense are none\", 0.0\n",
    "    if income is None:\n",
    "        return \"corporation lobbying for itself\", float(expense)\n",
    "    if expense is None:\n",
    "        return \"hired lobbying firm\", float(income)\n",
    "    else:\n",
    "        return \"both income and expense > $0\", float(income) + float(expense)\n",
    "\n",
    "\n",
    "def initialize_row(entity_df, result, filing_id):\n",
    "    # set up row dictionary using entity booleans\n",
    "    initialize_row_dict = dict(\n",
    "        zip(\n",
    "            [x.lower() for x in list(entity_df[\"name\"])],\n",
    "            [0] * len(list(entity_df[\"name\"])),\n",
    "        )\n",
    "    )\n",
    "    (\n",
    "        initialize_row_dict[\"who_is_lobbying\"],\n",
    "        initialize_row_dict[\"dollars_spent_lobbying\"],\n",
    "    ) = parse_dollars_spent(result[\"income\"], result[\"expenses\"])\n",
    "    initialize_row_dict[\"filing_id\"] = filing_id\n",
    "    initialize_row_dict[\"url\"] = result[\"url\"]\n",
    "    initialize_row_dict[\"filing_year\"] = int(result[\"filing_year\"])\n",
    "    initialize_row_dict[\"filing_period\"] = result[\"filing_period\"]\n",
    "    initialize_row_dict[\"lobbyist_posted_by_name\"] = result[\"posted_by_name\"]\n",
    "\n",
    "    initialize_row_dict[\"lobbyist_registrant_id\"] = result[\"registrant\"][\"id\"]\n",
    "    initialize_row_dict[\"lobbyist_registrant_name\"] = result[\"registrant\"][\"name\"]\n",
    "    initialize_row_dict[\"lobbyist_registrant_contact\"] = result[\"registrant\"][\n",
    "        \"contact_name\"\n",
    "    ]\n",
    "    initialize_row_dict[\"client_id\"] = result[\"client\"][\"id\"]\n",
    "    initialize_row_dict[\"client_client_id\"] = result[\"client\"][\"client_id\"]\n",
    "    initialize_row_dict[\"client_name\"] = result[\"client\"][\"name\"]\n",
    "    initialize_row_dict[\"affiliated_organizations_present\"] = False\n",
    "    if len(result[\"affiliated_organizations\"]) > 0:\n",
    "        initialize_row_dict[\"affiliated_organizations_present\"] = True\n",
    "    initialize_row_dict[\"convictions_present\"] = False\n",
    "    if len(result[\"conviction_disclosures\"]) > 0:\n",
    "        initialize_row_dict[\"convictions_present\"] = True\n",
    "    return initialize_row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lobbyists(df, lobbyists, details):\n",
    "    lobby_dict = {}\n",
    "    lobby_dict[\"firm_name\"] = details[\"lobbyist_registrant_name\"]\n",
    "    lobby_dict[\"client_name\"] = details[\"client_name\"]\n",
    "    lobby_dict[\"general_issue_code\"] = details[\"general_issue_code\"]\n",
    "    lobby_dict[\"description\"] = details[\"description\"]\n",
    "    lobby_dict[\"filing_period\"] = details[\"filing_period\"]\n",
    "    lobby_dict[\"filing_year\"] = details[\"filing_year\"]\n",
    "    lobby_dict[\"url\"] = details[\"url\"]\n",
    "    lobby_dict[\"filing_id\"] = details[\"filing_id\"]\n",
    "\n",
    "    lobby_list = []\n",
    "    # unpack lobbyists list\n",
    "    for lobbyist in lobbyists:\n",
    "        lobby_dict[\"name\"] = (\n",
    "            lobbyist[\"lobbyist\"][\"last_name\"]\n",
    "            + \", \"\n",
    "            + lobbyist[\"lobbyist\"][\"first_name\"]\n",
    "        )\n",
    "        lobby_dict[\"covered_position\"] = \"None\"\n",
    "        if \"covered_position\" in lobbyist:\n",
    "            lobby_dict[\"covered_position\"] = lobbyist[\"covered_position\"]\n",
    "        lobby_dict[\"id\"] = lobbyist[\"lobbyist\"][\"id\"]\n",
    "        lobby_list.append(lobby_dict.copy())\n",
    "\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"name\",\n",
    "                \"firm_name\",\n",
    "                \"client_name\",\n",
    "                \"general_issue_code\",\n",
    "                \"description\",\n",
    "                \"covered_position\",\n",
    "                \"filing_year\",\n",
    "                \"filing_period\",\n",
    "                \"url\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(lobby_list)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get govt entity names\n",
    "entity_df = pd.DataFrame(government_entities)\n",
    "\n",
    "corporations = [\n",
    "    \"Exxon\",\n",
    "    \"ExxonMobil\",\n",
    "]  # 'exxon' alone includes ExxonMobil Exxon Mobil Corp, Exxon Mobil Corporation, etc. ['Exxon Mobil'.upper(),'ExxonMobil'.upper(),'Exxon'\n",
    "\n",
    "row_list = (\n",
    "    []\n",
    ")  # initialize holder for each row (which corresponds to a single lobbying activity)\n",
    "max_page = 20\n",
    "\n",
    "filing_id = 0\n",
    "lobbyists_df = None\n",
    "for corporation in corporations:\n",
    "    for year in list(range(1999, 2025)):\n",
    "        page = 1\n",
    "        while page < max_page:\n",
    "            # print(f\"Querying page {page} for year {year}\")\n",
    "            query_filings = f'https://lda.senate.gov/api/v1/filings/?client_name=\"{corporation}\"&filing_period=year_end&filing_year={year}&page={page}'\n",
    "\n",
    "            f = requests.get(query_filings)\n",
    "\n",
    "            if \"detail\" in f.json():\n",
    "                break\n",
    "\n",
    "            results = f.json()[\"results\"]\n",
    "            page += 1  # increase the page for the next query\n",
    "            # print(f\"{len(results)} filings found\")\n",
    "            if len(results) < 25:\n",
    "                page = max_page\n",
    "\n",
    "            for result in results:\n",
    "                row_dict_base = initialize_row(entity_df, result, filing_id)\n",
    "                activities = result[\"lobbying_activities\"]\n",
    "\n",
    "                for activity_count, activity in enumerate(activities):\n",
    "                    row_dict = row_dict_base.copy()\n",
    "                    # set up row dictionary using entity booleans\n",
    "                    row_dict[\"activity_count\"] = activity_count\n",
    "                    row_dict[\"general_issue_code\"] = activity[\"general_issue_code\"]\n",
    "                    row_dict[\"description\"] = activity[\"description\"]\n",
    "                    lobbyists_df = parse_lobbyists(\n",
    "                        lobbyists_df, activity[\"lobbyists\"], row_dict\n",
    "                    )\n",
    "\n",
    "                    lobbyist_id_list = []\n",
    "                    for lobbyist in activity[\"lobbyists\"]:\n",
    "                        lobbyist_id_list.append(lobbyist[\"lobbyist\"][\"id\"])\n",
    "\n",
    "                    row_dict[\"lobbyist_ids\"] = \"; \".join(\n",
    "                        [\"None\" if x is None else str(x) for x in lobbyist_id_list]\n",
    "                    )\n",
    "                    for entity in activity[\"government_entities\"]:\n",
    "                        row_dict[entity[\"name\"].lower()] = 1\n",
    "\n",
    "                    row_list.append(row_dict.copy())\n",
    "\n",
    "                    row_dict.clear()\n",
    "                filing_id += 1\n",
    "\n",
    "tmp = pd.DataFrame(row_list)\n",
    "entities_influenced = tmp[[x.lower() for x in list(entity_df[\"name\"])]].sum()\n",
    "zeroed = list(entities_influenced[entities_influenced == 0].index)\n",
    "xom_df = tmp[[x for x in tmp.columns.values if x not in zeroed]]\n",
    "xom_df = xom_df.drop_duplicates(subset=xom_df.columns.difference([\"filing_id\"]))\n",
    "xom_unique_filing_ids = list(\n",
    "    xom_df.filing_id.unique()\n",
    ")  # keep a list of the non-duplicate filing ids\n",
    "\n",
    "# keep only right company aliases\n",
    "company_aliases = [\n",
    "    \"EXXON MOBIL CORP\",\n",
    "    \"EXXONMOBIL CHEMICAL CO\",\n",
    "    \"EXXON USA\",\n",
    "    \"EXXON CO USA\",\n",
    "    \"EXXON MOBIL CORPORATION\",\n",
    "    \"EXXON MOBIL PRODUCTION CO\",\n",
    "    \"EXXON MOBIL\",\n",
    "    \"EXXONMOBIL CORPORATION\",\n",
    "    \"EXXONMOBIL CORP\",\n",
    "    \"EXXON MOBILE\",\n",
    "    \"EXXONMOBIL GLOBAL SERVICES COMPANY\",\n",
    "    \"DCI GROUP, LLC, ON BEHALF OF EXXONMOBIL\",\n",
    "    \"EXXONMOBIL\",\n",
    "    \"HUNTON ANDREWS KURTH LLP (FORMERLY HUNTON & WILLIAMS LLP BEHALF OF EXXON MOBIL)\",\n",
    "    \"EXXON MOBIL COPORATION\",\n",
    "    \"EXXON MOBIL CORP.\",\n",
    "]\n",
    "xom_df = xom_df.loc[xom_df.client_name.isin(company_aliases)]\n",
    "\n",
    "\n",
    "lobbyists_df = lobbyists_df.loc[\n",
    "    (lobbyists_df.client_name.isin(company_aliases))\n",
    "    & (lobbyists_df.filing_id.isin(xom_unique_filing_ids))\n",
    "]\n",
    "\n",
    "xom_df[\"which_congress\"] = [which_congress(y) for y in xom_df[\"filing_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"which_congress\", \"description\"]].loc[\n",
    "    [x != \"\" for x in test_df.description]\n",
    "].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much money has exxonmobil spent lobbying congress in 25 years?\n",
    "xom_df[[\"dollars_spent_lobbying\", \"filing_id\"]].groupby(\"filing_id\").first()[\n",
    "    \"dollars_spent_lobbying\"\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_df.to_csv(\"xom_lda_filings.csv\")\n",
    "lobbyists_df.to_csv(\"xom_lobbyists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (\n",
    "    xom_df[\n",
    "        [\n",
    "            \"dollars_spent_lobbying\",\n",
    "            \"lobbyist_registrant_name\",\n",
    "            \"filing_id\",\n",
    "            \"filing_year\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby([\"lobbyist_registrant_name\", \"filing_id\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dollars_spent_df = (\n",
    "    tmp.groupby(\"lobbyist_registrant_name\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"dollars_spent_lobbying\": \"sum\",\n",
    "            \"filing_id\": \"count\",\n",
    "            \"filing_year\": \"min\",\n",
    "            \"filing_year\": \"min\",\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=\"dollars_spent_lobbying\", ascending=False)\n",
    ")\n",
    "total_dollars_spent_df.columns = [\n",
    "    \"dollars_spent_lobbying\",\n",
    "    \"total_lda_filings\",\n",
    "    \"earliest_filing_year\",\n",
    "]\n",
    "max_year_df = (\n",
    "    tmp[[\"lobbyist_registrant_name\", \"filing_year\"]]\n",
    "    .groupby(\"lobbyist_registrant_name\")\n",
    "    .agg({\"filing_year\": \"max\"})\n",
    ")\n",
    "max_year_df.columns = [\"latest_filing_year\"]\n",
    "total_dollars_spent_df = total_dollars_spent_df.merge(\n",
    "    max_year_df, right_index=True, left_index=True\n",
    ")\n",
    "total_dollars_spent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_dci_lobbyists = list(\n",
    "    lobbyists_df.loc[lobbyists_df.firm_name == \"DCI GROUP, L.L.C.\"].name.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = (\n",
    "    lobbyists_df[[\"name\", \"firm_name\"]]\n",
    "    .groupby(\"firm_name\")\n",
    "    .count()\n",
    "    .sort_values(by=\"name\")\n",
    ")\n",
    "counts_df.columns = [\"firm_total_filings\"]\n",
    "df = lobbyists_df.merge(counts_df, left_on=\"firm_name\", right_index=True)\n",
    "counts_df = (\n",
    "    lobbyists_df[[\"name\", \"firm_name\"]]\n",
    "    .groupby(\"name\")\n",
    "    .count()\n",
    "    .sort_values(by=\"firm_name\")\n",
    ")\n",
    "counts_df.columns = [\"total_number_of_filings\"]\n",
    "df = df.merge(counts_df, left_on=\"name\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobbyists_df[[\"name\", \"firm_name\", \"client_name\", \"total_number_of_filings\"]].groupby(\n",
    "    \"name\"\n",
    ").first().sort_values(by=\"total_number_of_filings\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob1 = requests.get(\n",
    "    'https://lda.senate.gov/api/v1/lobbyists/?registrant_name=\"DCI GROUP, L.L.C.\"&page=1'\n",
    ")\n",
    "lob2 = requests.get(\n",
    "    'https://lda.senate.gov/api/v1/lobbyists/?registrant_name=\"DCI GROUP, L.L.C.\"&page=2'\n",
    ")\n",
    "dci_lobbyists = lob1.json()[\"results\"] + lob2.json()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dci_lobbyists = []\n",
    "for dci in dci_lobbyists:\n",
    "    all_dci_lobbyists.append(dci[\"last_name\"] + \", \" + dci[\"first_name\"])\n",
    "\n",
    "sorted(all_dci_lobbyists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_df.loc[xom_df.f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_dci_lobbyists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xom_dict={}\n",
    "for x in xom:\n",
    "    xom_dict['year']=int(x['filing_year'])\n",
    "    xom_dict['rest']="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob = requests.get(\"https://lda.senate.gov/api/v1/lobbyists/\")\n",
    "filing_types = requests.get(\n",
    "    \"https://lda.senate.gov/api/v1/constants/filing/filingtypes/\"\n",
    ")\n",
    "general_issues = requests.get(\n",
    "    \"https://lda.senate.gov/api/v1/constants/filing/lobbyingactivityissues/\"\n",
    ")\n",
    "govt_entities = requests.get(\n",
    "    \"https://lda.senate.gov/api/v1/constants/filing/governmententities/\"\n",
    ")\n",
    "countries = requests.get(\"https://lda.senate.gov/api/v1/constants/general/countries/\")\n",
    "states = requests.get(\"https://lda.senate.gov/api/v1/constants/general/states/\")\n",
    "prefixes = requests.get(\"https://lda.senate.gov/api/v1/constants/lobbyist/prefixes/\")\n",
    "suffixes = requests.get(\"https://lda.senate.gov/api/v1/constants/lobbyist/suffixes/\")\n",
    "contribution_items = requests.get(\n",
    "    \"https://lda.senate.gov/api/v1/constants/contribution/itemtypes/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob = requests.get(\n",
    "    'https://lda.senate.gov/api/v1/lobbyists/?registrant_name=\"DCI GROUP, L.L.C.\"&page=2'\n",
    ")\n",
    "lob.json()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = []\n",
    "for page in range(1, 4):\n",
    "    c = requests.get(\n",
    "        f'https://lda.senate.gov/api/v1/contributions/?registrant_name=\"DCI GROUP, L.L.C.\"&filing_type=YY&page={page}'\n",
    "    )\n",
    "    contributions = contributions + c.json()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = []\n",
    "\n",
    "for dci in contributions:\n",
    "    row_dict = {}\n",
    "    for i in dci[\"contribution_items\"]:\n",
    "        row_dict[\"contribution_type\"] = i[\"contribution_type\"]\n",
    "        row_dict[\"contributor_name\"] = i[\"contributor_name\"]\n",
    "        row_dict[\"payee_name\"] = i[\"payee_name\"]\n",
    "        row_dict[\"honoree_name\"] = i[\"honoree_name\"]\n",
    "        row_dict[\"usd\"] = float(i[\"amount\"])\n",
    "        row_dict[\"date\"] = i[\"date\"]\n",
    "        row_dict[\"filing_year\"] = dci[\"filing_year\"]\n",
    "        row_dict[\"registrant_name\"] = dci[\"registrant\"][\"name\"]\n",
    "        row_list.append(row_dict.copy())\n",
    "dci_contributions_df = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_terms(x, terms):\n",
    "    for term in terms:\n",
    "        x = x.replace(term, \"\")\n",
    "\n",
    "    return x.split(\" (\")[0].title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    \"Senator \",\n",
    "    \"US \",\n",
    "    \"Rep. \",\n",
    "    \"U.S. \",\n",
    "    \"Representative \",\n",
    "    \"Sen. \",\n",
    "    \"Congressional \",\n",
    "    \"Candidate \",\n",
    "    \"Congressman \",\n",
    "    \"for \",\n",
    "    \"Friends of \",\n",
    "]\n",
    "\n",
    "print(dci_contributions_df.honoree_name.nunique())\n",
    "print(dci_contributions_df.stripped_honoree_name.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci_contributions_df.honoree_name.unique()\n",
    "terms = [\n",
    "    \"Senator \",\n",
    "    \"US \",\n",
    "    \"Rep. \",\n",
    "    \"Congresswoman \",\n",
    "    \"U.S. \",\n",
    "    \" 08\",\n",
    "    \" Jr.\",\n",
    "    \"Jr\",\n",
    "    \"Resident Commissioner of Puerto Rico \",\n",
    "    \"Senate \",\n",
    "    \"Campaign\",\n",
    "    \"Presidential \",\n",
    "    \"candidate \",\n",
    "    \"Candidate \",\n",
    "    \"Representative \",\n",
    "    \"Sen. \",\n",
    "    \"House \",\n",
    "    \"Congressional \",\n",
    "    \"Candidate \",\n",
    "    \"Representative-Elect \",\n",
    "    \"Campaign Committee\",\n",
    "    \"Committee\",\n",
    "    \"Congressman \",\n",
    "    \"for \",\n",
    "    \"Friends of \",\n",
    "    \" Senate\",\n",
    "    \" Congress\",\n",
    "    \"Friend of \",\n",
    "    \"- In-Kind Donation\",\n",
    "]\n",
    "dci_contributions_df[\"stripped_honoree_name\"] = [\n",
    "    strip_terms(x, terms) for x in dci_contributions_df.honoree_name\n",
    "]\n",
    "dci_contributions_df.stripped_honoree_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = list(dci_contributions_df.stripped_honoree_name.unique())\n",
    "dci_contributions_df[\"stripped_honoree_name\"] = [\n",
    "    x.strip() for x in dci_contributions_df[\"stripped_honoree_name\"]\n",
    "]\n",
    "dci_contributions_df[\"stripped_honoree_name_sim\"] = dci_contributions_df[\n",
    "    \"stripped_honoree_name\"\n",
    "]\n",
    "for y in yy:\n",
    "    dci_contributions_df[\"stripped_honoree_name_sim\"] = [\n",
    "        y if x in y else x for x in dci_contributions_df.stripped_honoree_name_sim\n",
    "    ]\n",
    "yy = list(dci_contributions_df.stripped_honoree_name_sim.unique())\n",
    "for y in yy:\n",
    "    dci_contributions_df[\"stripped_honoree_name_sim\"] = [\n",
    "        y if x in y else x for x in dci_contributions_df.stripped_honoree_name_sim\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = list(dci_contributions_df.stripped_honoree_name_sim.unique())\n",
    "for term, replacement in {\n",
    "    \"Allan\": \"Alan\",\n",
    "    \"Jim\": \"James\",\n",
    "    \"Gordan\": \"Gordon\",\n",
    "    \"&\": \"And\",\n",
    "    \"Georgians\": \"Johnny\",\n",
    "    \"M.\": \"Mary\",\n",
    "    \"Pete\": \"Peter\",\n",
    "}.items():\n",
    "    dci_contributions_df[\"stripped_honoree_name_sim\"] = [\n",
    "        x.replace(term, replacement)\n",
    "        for x in dci_contributions_df.stripped_honoree_name_sim\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci_contributions_df[[\"stripped_honoree_name_sim\", \"usd\"]].groupby(\n",
    "    \"stripped_honoree_name_sim\"\n",
    ").sum().sort_values(by=\"usd\", ascending=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from name_matching.name_matcher import NameMatcher\n",
    "\n",
    "# define a dataset with bank names\n",
    "df_a = pd.DataFrame({\"recipient1\": y})\n",
    "\n",
    "# alter each of the bank names a bit to test the matching\n",
    "df_b = pd.DataFrame({\"recipient2\": sorted(y)})\n",
    "\n",
    "# initialise the name matcher\n",
    "matcher = NameMatcher(\n",
    "    number_of_matches=5, legal_suffixes=True, common_words=False, top_n=50, verbose=True\n",
    ")\n",
    "\n",
    "# adjust the distance metrics to use\n",
    "matcher.set_distance_metrics([\"bag\", \"typo\", \"refined_soundex\"])\n",
    "\n",
    "# load the data to which the names should be matched\n",
    "matcher.load_and_process_master_data(\n",
    "    column=\"recipient1\", df_matching_data=df_a, transform=True\n",
    ")\n",
    "\n",
    "# perform the name matching on the data you want matched\n",
    "matches = matcher.match_names(to_be_matched=df_b, column_matching=\"recipient2\")\n",
    "\n",
    "# combine the datasets based on the matches\n",
    "# combined = pd.merge(df_a, matches, how='left', left_index=True, right_on='match_index')\n",
    "# combined#combined = pd.merge(combined, df_b, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches.drop(['match_name_0','score_0'],axis=1,inplace=True)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci_contributions_df[[\"filing_year\", \"usd\"]].groupby(\"filing_year\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms = []\n",
    "# lobbyists=lobbyists.json()['results']\n",
    "for lobby in lobbyists:\n",
    "    print(lobby)\n",
    "    firms.append(lobby[\"registrant\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payee = \"Friends of Max Baucus\".replace(\" \", \"%20\")\n",
    "year = \"2008\"\n",
    "contributor = \"Crossroads Strategies, LLC\".replace(\" \", \"%20\")\n",
    "year = \"2023\"\n",
    "query_all_contributions = f\"https://lda.senate.gov/api/v1/contributions/?contribution_payee={payee}&filing_year={year}\"\n",
    "c = requests.get(query_all_contributions)\n",
    "baucus = c.json()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor = \"Crossroads Strategies\".replace(\" \", \"%20\")\n",
    "year = \"2023\"\n",
    "query_all_contributions = f\"https://lda.senate.gov/api/v1/contributions/?contribution_contributor={contributor}&filing_year={year}\"\n",
    "c = requests.get(query_all_contributions)\n",
    "crossroads = c.json()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossroads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "for cc in baucus:\n",
    "    contributions = cc[\"contribution_items\"]\n",
    "    for i in contributions:\n",
    "        if i[\"payee_name\"].lower() == \"friends of max baucus\":\n",
    "            print(f'{i[\"contributor_name\"]}, amount: ${i[\"amount\"]}')\n",
    "            total = total + float(i[\"amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "govt_entities_df = pd.DataFrame(govt_entities.json())\n",
    "contribution_items_df = pd.DataFrame(contribution_items.json())\n",
    "general_issues_df = pd.DataFrame(general_issues.json())\n",
    "filing_types_df = pd.DataFrame(filing_types.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = requests.get(\"https://lda.senate.gov/api/v1/constants/\")\n",
    "constants.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = requests.get(r.json()[\"filings\"] + \"?client_name=exxon%20mobil&filing_year=2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.json()[\"results\"][0].keys()\n",
    "\n",
    "dictionary = rr.json()[\"results\"][0]\n",
    "dictionary = flatten(dictionary)\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"https://developer.nrel.gov/api/pvwatts/v8.json?api_key={config['apikey']}&lat={lat}&lon={lon}&system_capacity={config['kw']}&azimuth={azimuth}&tilt={tilt}&array_type=1&module_type=1&losses=10\"\n",
    "                response = requests.get(query, timeout=20)\n",
    "                info_dict[\"ac_annual\"] = response.json()[\"outputs\"][\"ac_annual\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects-7_KjhAaO-py3.11",
   "language": "python",
   "name": "projects-7_kjhaao-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
